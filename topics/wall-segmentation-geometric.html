<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Topic - Wall Segmentation in Floorplans (Geometric Approach)</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="topic-styles.css">
</head>
<body>
    <div class="notebook">
        <div class="notebook-page">
            <a href="../index.html" class="back-link">‚Üê Back to Topics</a>
            
            <div class="topic-header">
                <h1>Wall Segmentation in Floorplans using Geometric Approach</h1>
                <div class="topic-meta">
                    <p>Last update: July 2024</p>
                    <div class="topic-tags">
                        <span class="tag">Computer Vision</span>
                        <span class="tag">Geometric Processing</span>
                        <span class="tag">OpenCV</span>
                    </div>
                </div>
            </div>

            <div class="handwritten">
                <section class="section">
                    <h2>A Different Approach</h2>
                    <div class="content">
                        <p>While deep learning methods like Mask R-CNN work great, they need lots of training data and computational power. I wanted to try something simpler: using traditional computer vision techniques based on geometry.</p>
                        
                        <p>The idea is straightforward: floorplans have predictable geometric properties. Walls are continuous lines with consistent thickness, rooms are bounded by straight walls, and everything follows a grid-like structure. Why not use these properties directly?</p>

                        <h3>Why This Works</h3>
                        <ul>
                            <li>No training data needed</li>
                            <li>Much faster processing</li>
                            <li>Easy to understand and debug</li>
                            <li>Works well for clean, well-drawn floorplans</li>
                        </ul>

                        <div class="margin-note">
                            <strong>Note:</strong> This approach works best with clean, well-drawn architectural plans that follow standard geometric conventions.
                        </div>
                    </div>
                </section>

                <section class="section">
                    <h2>How It Works</h2>
                    <div class="content">
                        <p>The process has four main steps:</p>
                        <ol>
                            <li><strong>Preprocessing</strong> - Convert the image to binary (black and white) and invert it for better contour detection</li>
                            <li><strong>Contour Processing</strong> - Remove small noise contours and identify the outer boundary</li>
                            <li><strong>Corner Detection</strong> - Use Harris corner detection to find room corners, then draw lines to close gaps</li>
                            <li><strong>Wall Extraction</strong> - Apply morphological operations to ensure uniform wall thickness and separate rooms</li>
                        </ol>
                    </div>
                </section>

                <section class="section">
                    <h2>Code Implementation</h2>
                    <div class="content">
                        <h3>Key Code Files</h3>
                        <div class="code-files">
                            <div class="code-file">
                                <div class="code-header" onclick="toggleCode('room_detection')">
                                    <h4>1. Room Detection Script (room-detection.py)</h4>
                                    <button class="copy-button" onclick="copyCode('room_detection')">Copy</button>
                                </div>
                                <div class="code-content" id="room_detection">
                                    <pre class="code-block"><code>import cv2
import numpy as np

def preprocess_image(input_img, binarization_threshold=145):
    """
    Binarize and invert the grayscale image for better contour detection.
    :param input_img: Grayscale image of rooms.
    :param binarization_threshold: Threshold value for binarization.
    :return: Binary inverted image.
    """
    _, binary_img = cv2.threshold(input_img, binarization_threshold, 255, cv2.THRESH_BINARY)
    return cv2.bitwise_not(binary_img)

def remove_small_contours(binary_img, min_area):
    """
    Remove small contours based on the minimum area threshold.
    :param binary_img: Binary image with contours.
    :param min_area: Minimum area for contours to keep.
    :return: Image with small contours removed.
    """
    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mask = np.zeros_like(binary_img)
    for contour in contours:
        if cv2.contourArea(contour) > min_area:
            cv2.fillPoly(mask, [contour], 255)
    return mask

def detect_corners(input_img, threshold):
    """
    Detect corners in the image using the Harris corner detection.
    :param input_img: Grayscale image of rooms.
    :param threshold: Threshold for corner detection.
    :return: Binary image with corners detected.
    """
    dst = cv2.cornerHarris(np.float32(input_img), 2, 3, 0.04)
    dst = cv2.dilate(dst, None)
    return dst > threshold * dst.max()

def draw_lines_to_close_rooms(corners, img_color, max_length):
    """
    Draw lines to close off gaps in the rooms based on corner detection.
    :param corners: Binary image with corners detected.
    :param img_color: RGB image to draw lines on.
    :param max_length: Maximum length of gaps to close.
    """
    for y, row in enumerate(corners):
        x_coords = np.argwhere(row).flatten()
        for x1, x2 in zip(x_coords[:-1], x_coords[1:]):
            if x2 - x1 < max_length:
                cv2.line(img_color, (x1, y), (x2, y), (0, 0, 0), 1)

    for x, col in enumerate(corners.T):
        y_coords = np.argwhere(col).flatten()
        for y1, y2 in zip(y_coords[:-1], y_coords[1:]):
            if y2 - y1 < max_length:
                cv2.line(img_color, (x, y1), (x, y2), (0, 0, 0), 1)

def find_biggest_contour(input_img):
    """
    Find the largest contour in the image, assuming it's the outer boundary.
    :param input_img: Grayscale image of rooms.
    :return: Largest contour as a numpy array.
    """
    contours, _ = cv2.findContours(input_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    largest_contour = max(contours, key=cv2.contourArea)
    return largest_contour

def ensure_wall_thickness(image, thickness):
    """
    Ensure uniform wall thickness using morphological operations.
    :param image: Binary image with walls.
    :param thickness: Desired thickness of walls.
    :return: Image with uniform wall thickness.
    """
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (thickness, thickness))
    dilated = cv2.dilate(image, kernel, iterations=1)
    return cv2.erode(dilated, kernel, iterations=1)

def extract_rooms_and_walls(input_img, wall_thickness=3):
    """
    Detect rooms and extract walls with uniform thickness.
    :param input_img: Grayscale image of rooms.
    :param wall_thickness: Desired thickness of walls.
    :return: Tuple of (rooms, colored_house, walls_image)
    """
    binary_img = preprocess_image(input_img)
    mask = remove_small_contours(binary_img, min_area=25)

    input_img = cv2.bitwise_not(mask)
    corners = detect_corners(input_img, threshold=0.1)

    img_color = cv2.cvtColor(input_img, cv2.COLOR_GRAY2RGB)
    draw_lines_to_close_rooms(corners, img_color, max_length=100)

    largest_contour = find_biggest_contour(input_img)
    mask = np.zeros_like(input_img)
    cv2.fillPoly(mask, [largest_contour], 255)
    img_color[mask == 0] = [0, 0, 0]

    gray_img = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)
    _, labels = cv2.connectedComponents(gray_img)

    rooms = []
    for label in np.unique(labels)[1:]:
        component = labels == label
        if np.sum(component) < 500:
            continue

        r, c = np.nonzero(component)
        min_r, max_r = r.min(), r.max()
        min_c, max_c = c.min(), c.max()
        crop = np.zeros_like(gray_img).astype(np.uint8)
        crop[component] = input_img[component]
        crop = crop[min_r:max_r + 1, min_c:max_c + 1]

        crop = cv2.morphologyEx(crop, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=1)
        crop = cv2.dilate(crop, np.ones((1, 1), np.uint8), iterations=1)
        crop = cv2.erode(crop, np.ones((1, 1), np.uint8), iterations=1)

        img_color[min_r:max_r + 1, min_c:max_c + 1][crop > 0] = [np.random.randint(0, 255) for _ in range(3)]
        rooms.append(component)

    walls_image = np.zeros_like(input_img)
    walls_image[input_img == 0] = 255
    walls_image = ensure_wall_thickness(walls_image, wall_thickness)

    return rooms, img_color, walls_image

# Load the image
img = cv2.imread("input/floorplan-maya-official.jpg", 0)

# Process the image
rooms, colored_room_separation, walls_extracted = extract_rooms_and_walls(img)

# Save the images
cv2.imwrite('output/colored-room-separation.jpg', colored_room_separation)
cv2.imwrite('output/walls-extracted.jpg', walls_extracted)

# Display and save the results
cv2.imshow('Colored Room Separation', colored_room_separation)
cv2.imshow('Walls Image', walls_extracted)
cv2.waitKey(0)
cv2.destroyAllWindows()</code></pre>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <section class="section">
                    <h2>Results</h2>
                    <div class="content">
                        <div class="results-gallery">
                            <div class="result-item">
                                <h3>Input Floorplan</h3>
                                <img src="../images/input-floorplan.jpg" alt="Input floorplan">
                            </div>
                            <div class="result-item">
                                <h3>Room Segmentation</h3>
                                <img src="../images/colored-room-separation.jpg" alt="Colored room separation">
                            </div>
                            <div class="result-item">
                                <h3>Extracted Walls</h3>
                                <img src="../images/walls-extracted.jpg" alt="Extracted walls">
                            </div>
                        </div>

                        <div class="margin-note">
                            <strong>Note:</strong> Works best with clean, well-drawn floorplans.
                        </div>
                    </div>
                </section>

                <section class="section">
                    <h2>Limitations & Next Steps</h2>
                    <div class="content">
                        <p>This approach works well for clean floorplans, but it has some limitations:</p>
                        <ul>
                            <li>Sensitive to image quality and noise</li>
                            <li>Struggles with very complex architectural elements</li>
                            <li>Can't handle overlapping or ambiguous wall structures well</li>
                        </ul>

                        <p>For more complex cases, combining this with deep learning could work better check out my <a href="wall-segmentation.html">Mask R-CNN implementation</a> for comparison.</p>
                    </div>
                </section>
            </div>
        </div>
    </div>

    <script>
        function toggleCode(id) {
            const content = document.getElementById(id);
            content.classList.toggle('active');
        }

        function copyCode(id) {
            const codeBlock = document.getElementById(id).querySelector('code');
            const textArea = document.createElement('textarea');
            textArea.value = codeBlock.textContent;
            document.body.appendChild(textArea);
            textArea.select();
            document.execCommand('copy');
            document.body.removeChild(textArea);
            
            // Show copied notification
            const button = event.target;
            const originalText = button.textContent;
            button.textContent = 'Copied!';
            setTimeout(() => {
                button.textContent = originalText;
            }, 2000);
        }
    </script>
</body>
</html> 