<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Topic - Motion Detection using Background Subtraction</title>
    <link rel="stylesheet" href="../style.css">
    <style>
        /* Additional styles for the notebook page */
        .notebook-page {
            background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="100" height="100" viewBox="0 0 100 100"><rect width="100" height="100" fill="none" stroke="%23e0e0e0" stroke-width="1"/><line x1="0" y1="20" x2="100" y2="20" stroke="%23e0e0e0" stroke-width="1"/><line x1="0" y1="40" x2="100" y2="40" stroke="%23e0e0e0" stroke-width="1"/><line x1="0" y1="60" x2="100" y2="60" stroke="%23e0e0e0" stroke-width="1"/><line x1="0" y1="80" x2="100" y2="80" stroke="%23e0e0e0" stroke-width="1"/></svg>');
            background-size: 100px 100px;
            padding: 40px;
            position: relative;
        }

        .notebook-page::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(255, 255, 255, 0.9);
            z-index: -1;
        }

        .page-number {
            position: absolute;
            bottom: 20px;
            right: 20px;
            font-size: 0.8em;
            color: var(--accent-color);
        }

        .back-link {
            position: absolute;
            top: 20px;
            left: 20px;
            text-decoration: none;
            color: var(--accent-color);
            font-size: 1.2em;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        .topic-header {
            text-align: center;
            margin-bottom: 40px;
            position: relative;
        }

        .topic-header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-family: 'Times New Roman', serif;
        }

        .topic-meta {
            font-style: italic;
            color: var(--accent-color);
        }

        .section {
            margin-bottom: 30px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.8);
            border: 1px solid var(--line-color);
            box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1);
        }

        .section h2 {
            border-bottom: 2px solid var(--line-color);
            padding-bottom: 10px;
            margin-top: 0;
            font-family: 'Times New Roman', serif;
        }

        .handwritten {
            font-family: 'Courier New', Courier, monospace;
            font-size: 1.1em;
            line-height: 1.8;
        }

        .margin-note {
            float: right;
            width: 200px;
            margin: 0 0 20px 20px;
            padding: 10px;
            background: var(--highlight-color);
            border: 1px solid var(--line-color);
            font-style: italic;
        }

        .algorithm-comparison {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }

        .algorithm-comparison h4 {
            color: #2c3e50;
            margin-top: 0;
            margin-bottom: 10px;
        }

        .algorithm-comparison ul {
            padding-left: 20px;
            margin: 0;
        }

        .algorithm-comparison li {
            margin-bottom: 5px;
        }

        .code-block {
            background-color: #1e1e1e;
            color: #d4d4d4;
            padding: 15px;
            border-radius: 5px;
            position: relative;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 14px;
            line-height: 1.5;
            margin: 10px 0;
            overflow-x: auto;
        }

        .code-header {
            background-color: #2d2d2d;
            padding: 8px 15px;
            border-radius: 5px 5px 0 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
            cursor: pointer;
        }

        .code-header h4 {
            margin: 0;
            color: #d4d4d4;
            font-size: 14px;
        }

        .copy-button {
            background-color: #3e3e3e;
            color: #d4d4d4;
            border: none;
            padding: 5px 10px;
            border-radius: 3px;
            cursor: pointer;
            font-size: 12px;
        }

        .copy-button:hover {
            background-color: #4e4e4e;
        }

        .code-content {
            display: none;
            margin-top: 0;
        }

        .code-content.active {
            display: block;
        }

        .code-files {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }

        .code-file {
            width: 100%;
        }

        .results-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .result-item {
            text-align: center;
        }

        .result-item img {
            max-width: 100%;
            border: 1px solid var(--line-color);
            box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1);
        }

        .result-item p {
            margin-top: 10px;
            font-style: italic;
        }

        .algorithm-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        .algorithm-table th, .algorithm-table td {
            padding: 12px;
            text-align: left;
            border: 1px solid #ddd;
            vertical-align: top;
        }

        .algorithm-table th {
            background-color: #f8f9fa;
            font-weight: bold;
        }

        .algorithm-table ul {
            margin: 0;
            padding-left: 20px;
        }

        .algorithm-table li {
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <div class="notebook">
        <div class="notebook-page">
            <a href="../index.html" class="back-link">‚Üê Back to Topics</a>
            
            <div class="topic-header">
                <h1>Motion Detection using Background Subtraction Techniques</h1>
                <div class="topic-meta">
                    <p>Last update: December 2023</p>
                    <div class="topic-tags">
                        <span class="tag">Computer Vision</span>
                        <span class="tag">Motion Detection</span>
                        <span class="tag">OpenCV</span>
                        <span class="tag">Bg Subtraction</span>
                    </div>
                </div>
            </div>

            <div class="handwritten">
                <section class="section">
                    <h2>Overview</h2>
                    <div class="content">
                        <p>This project explores different background subtraction algorithms for detecting motion in videos. I tested five OpenCV algorithms (GMG, MOG, MOG2, KNN, CNT) and implemented a custom temporal median filter approach. The goal was to see how each algorithm performs on different types of videos such as car traffic, beach scenes with people walking, and other scenarios.</p>
                    </div>
                </section>

                <section class="section">
                    <h2>Algorithms Tested</h2>
                    <div class="content">
                        <h3>OpenCV Background Subtractors</h3>
                        <p>I tested five built-in OpenCV algorithms:</p>
                        <ul>
                            <li><strong>GMG</strong> - Gaussian Mixture-based, needs initialization frames</li>
                            <li><strong>MOG</strong> - Mixture of Gaussians</li>
                            <li><strong>MOG2</strong> - Improved MOG with shadow detection (performed best overall)</li>
                            <li><strong>KNN</strong> - K-Nearest Neighbors based</li>
                            <li><strong>CNT</strong> - Counting-based, fastest processing</li>
                        </ul>

                        <h3>Temporal Median Filter approach</h3>
                        <ol>
                            <li>Sample 25 random frames from the video</li>
                            <li>Calculate the median of all frames to create a background model</li>
                            <li>For each frame, compute the difference from the background</li>
                            <li>Apply Otsu's thresholding to detect moving objects</li>
                        </ol>

                        <h3>Post-Processing</h3>
                        <p>Applied morphological operations to clean up the detection results:</p>
                        <ul>
                            <li><strong>Dilation</strong> - Fill small gaps</li>
                            <li><strong>Opening</strong> - Remove noise</li>
                            <li><strong>Closing</strong> - Fill holes in detected objects</li>
                        </ul>
                    </div>
                </section>

                <section class="section">
                    <h2>Code Implementation</h2>
                    <div class="content">
                        <h3>Key Code Files</h3>
                        <div class="code-files">
                            <div class="code-file">
                                <div class="code-header" onclick="toggleCode('bg_subtractor')">
                                    <h4>1. Background Subtraction Algorithms (other-bg-substractor-algorithms.py)</h4>
                                    <button class="copy-button" onclick="copyCode('bg_subtractor')">Copy</button>
                                </div>
                                <div class="code-content" id="bg_subtractor">
                                    <pre class="code-block"><code>import sys
from random import randint

import cv2
import numpy as np

TEXT_COLOR = (randint(0, 255), randint(0, 255), randint(0, 255))
BORDER_COLOR = (randint(0, 255), randint(0, 255), randint(0, 255))
FONT = cv2.FONT_HERSHEY_SIMPLEX
VIDEO_SOURCE = "videos-materials/input/birds.mp4"

BGS_TYPES = ['GMG', 'MOG2', 'MOG', 'KNN', 'CNT']


def get_kernel(KERNEL_TYPE):
    if KERNEL_TYPE == 'dilation':
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    if KERNEL_TYPE == 'opening':
        kernel = np.ones((3, 3), np.uint8)
    if KERNEL_TYPE == 'closing':
        kernel = np.ones((3, 3), np.uint8)
    return kernel


def get_filter(img, filter):
    if filter == 'closing':
        return cv2.morphologyEx(img, cv2.MORPH_OPEN, get_kernel('closing'), iterations=2)
    if filter == 'opening':
        return cv2.morphologyEx(img, cv2.MORPH_OPEN, get_kernel('opening'), iterations=2)
    if filter == 'dilation':
        return cv2.dilate(img, get_kernel('dilation'), iterations=2)
    if filter == 'combine':
        closing = cv2.morphologyEx(img, cv2.MORPH_OPEN, get_kernel('closing'), iterations=2)
        opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, get_kernel('opening'), iterations=2)
        dilation = cv2.dilate(img, get_kernel('dilation'), iterations=2)
        return dilation


def get_bgsubtractor(BGS_TYPE):
    if BGS_TYPE == 'GMG':
        return cv2.bgsegm.createBackgroundSubtractorGMG(initializationFrames=120, decisionThreshold=0.8)
    if BGS_TYPE == 'MOG':
        return cv2.bgsegm.createBackgroundSubtractorMOG(history=200, nmixtures=5, backgroundRatio=0.7, noiseSigma=0)
    if BGS_TYPE == 'MOG2':
        return cv2.createBackgroundSubtractorMOG2(history=500, detectShadows=True, varThreshold=100)
    if BGS_TYPE == 'KNN':
        return cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=400, detectShadows=True)
    if BGS_TYPE == 'CNT':
        return cv2.bgsegm.createBackgroundSubtractorCNT(minPixelStability=15, useHistory=True,
                                                        maxPixelStability=15 * 60, isParallel=True)
    print('Invalid detector')
    sys.exit()


cap = cv2.VideoCapture(VIDEO_SOURCE)

# MOG2 is the best for the given video Cars
BGS_TYPE = BGS_TYPES[2]
bg_subtractor = get_bgsubtractor(BGS_TYPE)


def main():
    while cap.isOpened():
        ok, frame = cap.read()

        if not ok:
            print('Error reading video file')
            break

        frame = cv2.resize(frame, (0, 0), fx=0.2, fy=0.2)
        bg_mask = bg_subtractor.apply(frame)
        fg_mask = get_filter(bg_mask, 'dilation')
        fg_mask_closing = get_filter(fg_mask, 'closing')
        fg_mask_opening = get_filter(fg_mask, 'opening')
        fg_mask_combine = get_filter(fg_mask, 'combine')

        res = cv2.bitwise_and(frame, frame, mask=fg_mask)
        res_closing = cv2.bitwise_and(frame, frame, mask=fg_mask_closing)
        res_opening = cv2.bitwise_and(frame, frame, mask=fg_mask_opening)
        res_combine = cv2.bitwise_and(frame, frame, mask=fg_mask_combine)

        cv2.putText(res_combine, 'BG subtractor: ' + BGS_TYPE, (10, 50), FONT, 1, BORDER_COLOR, 2, cv2.LINE_AA)

        cv2.imshow('Combine final', res_combine)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break


main()
cap.release()
cv2.destroyAllWindows()</code></pre>
                                </div>
                            </div>

                            <div class="code-file">
                                <div class="code-header" onclick="toggleCode('temporal_median')">
                                    <h4>2. Temporal Median Filter (temporal-median-filter.py)</h4>
                                    <button class="copy-button" onclick="copyCode('temporal_median')">Copy</button>
                                </div>
                                <div class="code-content" id="temporal_median">
                                    <pre class="code-block"><code>import numpy as np
import cv2

# Define the source and output video files
VIDEO_SOURCE = 'videos-materials/input/beach.mp4'
VIDEO_OUT = 'videos-materials/output/temporal_median_filter.avi'

# Capture video from the source file
cap = cv2.VideoCapture(VIDEO_SOURCE)
has_frame, frame = cap.read()
print(has_frame, frame.shape)

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'XVID')
writer = cv2.VideoWriter(VIDEO_OUT, fourcc, 25, (frame.shape[1], frame.shape[0]), False)

# Get a random selection of frame IDs
frames_ids = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=25)
print(frames_ids)

# Capture the selected frames
frames = []
for fid in frames_ids:
    cap.set(cv2.CAP_PROP_POS_FRAMES, fid)
    has_frame, frame = cap.read()
    frames.append(frame)

# Calculate the median frame
median_frame = np.median(frames, axis=0).astype(np.uint8)
cv2.imwrite('videos-materials/output/model-median-frame.jpg', median_frame)

# Reset the video to the first frame and convert the median frame to grayscale
cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
gray_median_frame = cv2.cvtColor(median_frame, cv2.COLOR_BGR2GRAY)

while True:
    has_frame, frame = cap.read()

    if not has_frame:
        print('No frame detected')
        break

    # Convert the current frame to grayscale
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    # Compute the absolute difference between the current frame and the background model
    dframe = cv2.absdiff(frame_gray, gray_median_frame)
    # Apply a threshold to get a binary image
    th, dframe = cv2.threshold(dframe, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)

    print(th)

    # Display the binary image
    cv2.imshow('frame', dframe)
    writer.write(dframe)

    # Exit loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release input
writer.release()
cap.release()
cv2.destroyAllWindows()</code></pre>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <section class="section">
                    <h2>Results</h2>
                    <div class="content">
                        <h3>Background Subtraction Algorithms - Car Traffic</h3>
                        <div class="results-gallery">
                            <div class="result-item">
                                <h4>Original vs Motion Detection Output</h4>
                                <img src="../images/cars-comparison-video-1-min.gif" alt="Comparison showing original video and motion detection output">
                                <p>Side-by-side comparison of original car traffic video and motion detection results using background subtraction algorithms</p>
                            </div>
                        </div>

                        <h3>Temporal Median Filter - Beach Scene</h3>
                        <div class="results-gallery">
                            <div class="result-item">
                                <h4>Bg Model (Median Frame)</h4>
                                <img src="../images/model-median-frame.jpg" alt="Median frame background model">
                                <p>Background model created from 25 randomly sampled frames</p>
                            </div>
                            <div class="result-item">
                                <h4>Input Video</h4>
                                <img src="../images/beach-input.gif" alt="Beach input video with person walking">
                                <p>Original beach video with person walking</p>
                            </div>
                            <div class="result-item">
                                <h4>Motion Detection Output (slowed down)</h4>
                                <img src="../images/beach-temporal-median-output.gif" alt="Temporal median filter motion detection output">
                                <p>Detected motion using temporal median filter with Otsu's thresholding</p>
                            </div>
                        </div>

                        <div class="algorithm-comparison">
                            <h4>What I Found</h4>
                            <ul>
                                <li><strong>MOG2</strong> worked best overall - good balance of speed and accuracy, has built-in shadow detection</li>
                                <li><strong>CNT</strong> was the fastest but less accurate</li>
                                <li><strong>KNN</strong> handled complex scenes well but slower</li>
                                <li><strong>Temporal Median Filter</strong> simple and effective for static backgrounds</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <section class="section">
                    <h2>Takeaways</h2>
                    <div class="content">
                        <ul>
                            <li>Different algorithms work better for different scenarios</li>
                            <li>Morphological operations (dilation, opening, closing) really help clean up the results</li>
                            <li>MOG2's shadow detection made a big difference in outdoor videos</li>
                            <li>The temporal median filter is a simple alternative that works well for static backgrounds</li>
                        </ul>
                    </div>
                </section>

                <script>
                    function toggleCode(id) {
                        const content = document.getElementById(id);
                        content.classList.toggle('active');
                    }

                    function copyCode(id) {
                        const codeBlock = document.getElementById(id).querySelector('code');
                        const textArea = document.createElement('textarea');
                        textArea.value = codeBlock.textContent;
                        document.body.appendChild(textArea);
                        textArea.select();
                        document.execCommand('copy');
                        document.body.removeChild(textArea);
                        
                        // Show copied notification
                        const button = event.target;
                        const originalText = button.textContent;
                        button.textContent = 'Copied!';
                        setTimeout(() => {
                            button.textContent = originalText;
                        }, 2000);
                    }
                </script>

                <section class="section">
                    <h2>Additional Resources</h2>
                    <div class="content">
                        <ul>
                            <li>
                                <a href="https://docs.opencv.org/4.x/d1/dc5/tutorial_background_subtraction.html" target="_blank">OpenCV Background Subtraction Tutorial</a>
                                <p>Official OpenCV documentation covering the implementation and usage of various background subtraction algorithms.</p>
                            </li>
                            <li>
                                <a href="https://docs.opencv.org/3.4/d7/df3/group__bgsegm.html" target="_blank">OpenCV Background Segmentation Module</a>
                                <p>Detailed API reference for the background segmentation module including GMG, MOG, and CNT algorithms.</p>
                            </li>
                            <li>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320313003294" target="_blank">Improved Adaptive Gaussian Mixture Model (MOG2)</a>
                                <p>Research paper describing the improvements in MOG2 over the original MOG algorithm.</p>
                            </li>
                        </ul>
                    </div>
                </section>
            </div>

            <div class="page-number">Page 1</div>
        </div>
    </div>
</body>
</html>
